{"cells":[{"cell_type":"markdown","id":"51add8c9","metadata":{"id":"51add8c9"},"source":["# Imports"]},{"cell_type":"code","source":["pip install torch-scatter\n","pip install torch-geometric\n","pip install torch-sparse"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lmm7hB906IkW","executionInfo":{"status":"ok","timestamp":1718993888237,"user_tz":-120,"elapsed":412719,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"15ff1ba3-af4d-42ca-b5a4-4bc3cff91ccd"},"id":"Lmm7hB906IkW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-scatter\n","  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m956.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: torch-scatter\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=507268 sha256=6f85c3493bef4d0f2ed42904bafb9c93fc1a755b0ecabe14fa6b3caaec967069\n","  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n","Successfully built torch-scatter\n","Installing collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2\n"]}]},{"cell_type":"code","execution_count":null,"id":"59f2afec","metadata":{"id":"59f2afec"},"outputs":[],"source":["# import required modules\n","import random\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn import model_selection, metrics, preprocessing\n","import copy\n","from torch_geometric.utils import degree\n","\n","import torch\n","from torch import nn, optim, Tensor\n","\n","from torch_sparse import SparseTensor, matmul\n","\n","from torch_geometric.utils import structured_negative_sampling\n","from torch_geometric.data import download_url, extract_zip\n","from torch_geometric.nn.conv.gcn_conv import gcn_norm\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.typing import Adj"]},{"cell_type":"markdown","id":"a5e5bbd8","metadata":{"id":"a5e5bbd8"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":74,"id":"c5b6bf8a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5b6bf8a","executionInfo":{"status":"ok","timestamp":1719004380042,"user_tz":-120,"elapsed":1908,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"726941f1-3160-4e98-8ce1-e21e19557fdc"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using existing file ml-latest-small.zip\n","Extracting ./ml-latest-small.zip\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# download the dataset\n","# https://grouplens.org/datasets/movielens/\n","# \"Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018\"\n","url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n","extract_zip(download_url(url, '.'), '.')\n","\n","movie_path = './ml-latest-small/movies.csv'\n","rating_path = './ml-latest-small/ratings.csv'\n","user_path = './ml-latest-small/users.csv'\n","\n","from google.colab import drive\n","\n","\n","drive.mount('/content/drive')\n","import os\n","\n","#os.chdir('drive/MyDrive/Colab Notebooks/GraphML/')\n","#model= torch.load('embs.pt')\n","# print(model)"]},{"cell_type":"code","execution_count":null,"id":"5248f04b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"5248f04b","executionInfo":{"status":"ok","timestamp":1718993915484,"user_tz":-120,"elapsed":282,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"baa56725-c3f9-4ce5-b18b-79f17af2244e"},"outputs":[{"output_type":"stream","name":"stdout","text":["   userId  movieId  rating  timestamp\n","0       1        1     4.0  964982703\n","1       1        3     4.0  964981247\n","2       1        6     4.0  964982224\n","3       1       47     5.0  964983815\n","4       1       50     5.0  964982931\n","9724\n","610\n"]},{"output_type":"execute_result","data":{"text/plain":["              userId        movieId         rating     timestamp\n","count  100836.000000  100836.000000  100836.000000  1.008360e+05\n","mean      326.127564   19435.295718       3.501557  1.205946e+09\n","std       182.618491   35530.987199       1.042529  2.162610e+08\n","min         1.000000       1.000000       0.500000  8.281246e+08\n","25%       177.000000    1199.000000       3.000000  1.019124e+09\n","50%       325.000000    2991.000000       3.500000  1.186087e+09\n","75%       477.000000    8122.000000       4.000000  1.435994e+09\n","max       610.000000  193609.000000       5.000000  1.537799e+09"],"text/html":["\n","  <div id=\"df-ad0b5b7e-19d2-42df-9780-b89f3e2d9935\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>100836.000000</td>\n","      <td>100836.000000</td>\n","      <td>100836.000000</td>\n","      <td>1.008360e+05</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>326.127564</td>\n","      <td>19435.295718</td>\n","      <td>3.501557</td>\n","      <td>1.205946e+09</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>182.618491</td>\n","      <td>35530.987199</td>\n","      <td>1.042529</td>\n","      <td>2.162610e+08</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>8.281246e+08</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>177.000000</td>\n","      <td>1199.000000</td>\n","      <td>3.000000</td>\n","      <td>1.019124e+09</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>325.000000</td>\n","      <td>2991.000000</td>\n","      <td>3.500000</td>\n","      <td>1.186087e+09</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>477.000000</td>\n","      <td>8122.000000</td>\n","      <td>4.000000</td>\n","      <td>1.435994e+09</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>610.000000</td>\n","      <td>193609.000000</td>\n","      <td>5.000000</td>\n","      <td>1.537799e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad0b5b7e-19d2-42df-9780-b89f3e2d9935')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ad0b5b7e-19d2-42df-9780-b89f3e2d9935 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ad0b5b7e-19d2-42df-9780-b89f3e2d9935');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bfcf2aba-7309-4a10-b455-becae763343b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfcf2aba-7309-4a10-b455-becae763343b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bfcf2aba-7309-4a10-b455-becae763343b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"rating_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35545.40345112833,\n        \"min\": 1.0,\n        \"max\": 100836.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          326.12756356856676,\n          325.0,\n          100836.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68674.51077210998,\n        \"min\": 1.0,\n        \"max\": 193609.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19435.2957177992,\n          2991.0,\n          100836.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35649.872091978,\n        \"min\": 0.5,\n        \"max\": 100836.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.501556983616962,\n          3.5,\n          100836.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 555443207.4882222,\n        \"min\": 100836.0,\n        \"max\": 1537799250.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1205946087.3684695,\n          1186086662.0,\n          100836.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["rating_df = pd.read_csv(rating_path)\n","\n","print(rating_df.head())\n","\n","print(len(rating_df['movieId'].unique()))\n","print(len(rating_df['userId'].unique()))\n","\n","rating_df.describe()\n"]},{"cell_type":"code","execution_count":null,"id":"d3c20490","metadata":{"id":"d3c20490"},"outputs":[],"source":["# perform encoding preprocessing to ensure that user_id and item_id are both\n","# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n","lbl_user = preprocessing.LabelEncoder()\n","lbl_movie = preprocessing.LabelEncoder()\n","\n","rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n","rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"]},{"cell_type":"code","execution_count":null,"id":"5527b80b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5527b80b","executionInfo":{"status":"ok","timestamp":1718993933432,"user_tz":-120,"elapsed":243,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"7a1a928d-0049-4a97-fef5-c480d03126d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["609\n","9723\n"]}],"source":["print(rating_df.userId.max())\n","print(rating_df.movieId.max())"]},{"cell_type":"code","execution_count":null,"id":"ea7018cc","metadata":{"id":"ea7018cc","outputId":"be547bc2-bb1c-4719-b4cf-909b6dd46f2d"},"outputs":[{"data":{"text/plain":["4.0    26818\n","3.0    20047\n","5.0    13211\n","3.5    13136\n","4.5     8551\n","2.0     7551\n","2.5     5550\n","1.0     2811\n","1.5     1791\n","0.5     1370\n","Name: rating, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["rating_df.rating.value_counts()"]},{"cell_type":"code","execution_count":null,"id":"a1e6b7e5","metadata":{"id":"a1e6b7e5"},"outputs":[],"source":["# load edges between users and movies\n","def load_edge_csv(df,\n","                  src_index_col,\n","                  dst_index_col,\n","                  link_index_col,\n","                  rating_threshold=3):\n","    \"\"\"Loads csv containing edges between users and items\n","\n","    Args:\n","        src_index_col (str): column name of users\n","        dst_index_col (str): column name of items\n","        link_index_col (str): column name of user item interaction\n","        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n","\n","    Returns:\n","        list of list: edge_index -- 2 by N matrix containing the node ids of N user-item edges\n","        N here is the number of interactions\n","    \"\"\"\n","\n","    edge_index = None\n","\n","    # Constructing COO format edge_index from input rating events\n","\n","    # get user_ids from rating events in the order of occurance\n","    src = [user_id for user_id in  df['userId']]\n","    # get movie_id from rating events in the order of occurance\n","    dst = [(movie_id) for movie_id in df['movieId']]\n","\n","    # apply rating threshold\n","    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n","\n","    edge_index = [[], []]\n","    for i in range(edge_attr.shape[0]):\n","        if edge_attr[i]:\n","            edge_index[0].append(src[i])\n","            edge_index[1].append(dst[i])\n","    return edge_index"]},{"cell_type":"code","execution_count":null,"id":"49a1fc26","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49a1fc26","executionInfo":{"status":"ok","timestamp":1718993939209,"user_tz":-120,"elapsed":962,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"ff4c3354-fcf4-4e30-a45b-db5ea02dee1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2 x 48580\n"]}],"source":["edge_index = load_edge_csv(\n","    rating_df,\n","    src_index_col='userId',\n","    dst_index_col='movieId',\n","    link_index_col='rating',\n","    rating_threshold=3.5,\n",")\n","\n","print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n"]},{"cell_type":"code","execution_count":null,"id":"fc37da10","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc37da10","executionInfo":{"status":"ok","timestamp":1718993941647,"user_tz":-120,"elapsed":235,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"e2f8d5d1-ac93-4e6d-b5ef-1774cad542ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   0,    0,    0,  ...,  609,  609,  609],\n","        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n","torch.Size([2, 48580])\n"]}],"source":["# Convert to tensor\n","# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n","edge_index = torch.LongTensor(edge_index)\n","print(edge_index)\n","print(edge_index.size())"]},{"cell_type":"code","execution_count":null,"id":"8c38603a","metadata":{"id":"8c38603a"},"outputs":[],"source":["# Note: this is the total num_users and num_movies before we apply the rating_threshold\n","num_users = len(rating_df['userId'].unique())\n","num_movies = len(rating_df['movieId'].unique())"]},{"cell_type":"code","execution_count":null,"id":"b4e70928","metadata":{"id":"b4e70928"},"outputs":[],"source":["num_interactions = edge_index.shape[1]\n","\n","# split the edges of the graph using a 80/10/10 train/validation/test split\n","all_indices = [i for i in range(num_interactions)]\n","\n","train_indices, test_indices = train_test_split(all_indices,\n","                                               test_size=0.2,\n","                                               random_state=1)\n","\n","val_indices, test_indices = train_test_split(test_indices,\n","                                             test_size=0.5,\n","                                             random_state=1)\n","\n","train_edge_index = edge_index[:, train_indices]\n","val_edge_index = edge_index[:, val_indices]\n","test_edge_index = edge_index[:, test_indices]"]},{"cell_type":"code","execution_count":null,"id":"ffc7e5e8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffc7e5e8","executionInfo":{"status":"ok","timestamp":1718994005553,"user_tz":-120,"elapsed":220,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"cca65060-9af8-4ca3-e2f3-7b59ef6c8f79"},"outputs":[{"output_type":"stream","name":"stdout","text":["num_users 610, num_movies 9724, num_interactions 48580\n","train_edge_index tensor([[ 605,  110,  442,  ...,   65,  161,  427],\n","        [1110, 9619, 1283,  ..., 4640,  443,  827]])\n","10334\n","torch.Size([609])\n","torch.Size([5676])\n"]}],"source":["print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n","print(f\"train_edge_index {train_edge_index}\")\n","print((num_users + num_movies))\n","print(torch.unique(train_edge_index[0]).size())\n","print(torch.unique(train_edge_index[1]).size())\n"]},{"cell_type":"code","execution_count":null,"id":"e5daf702","metadata":{"id":"e5daf702"},"outputs":[],"source":["def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n","    R = torch.zeros((num_users, num_movies))\n","    for i in range(len(input_edge_index[0])):\n","        row_idx = input_edge_index[0][i]\n","        col_idx = input_edge_index[1][i]\n","        R[row_idx][col_idx] = 1\n","\n","    R_transpose = torch.transpose(R, 0, 1)\n","    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n","    adj_mat[: num_users, num_users :] = R.clone()\n","    adj_mat[num_users :, : num_users] = R_transpose.clone()\n","    adj_mat_coo = adj_mat.to_sparse_coo()\n","    adj_mat_coo = adj_mat_coo.indices()\n","    return adj_mat_coo"]},{"cell_type":"code","execution_count":null,"id":"005195ba","metadata":{"id":"005195ba"},"outputs":[],"source":["def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n","    sparse_input_edge_index = SparseTensor(row=input_edge_index[0],\n","                                           col=input_edge_index[1],\n","                                           sparse_sizes=((num_users + num_movies), num_users + num_movies))\n","    adj_mat = sparse_input_edge_index.to_dense()\n","    interact_mat = adj_mat[: num_users, num_users :]\n","    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n","    return r_mat_edge_index"]},{"cell_type":"code","execution_count":null,"id":"f6e41ca6","metadata":{"id":"f6e41ca6"},"outputs":[],"source":["# convert from r_mat (interaction matrix) edge index to adjescency matrix's edge index\n","# so we can feed it to model\n","train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n","val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n","test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"]},{"cell_type":"code","execution_count":null,"id":"9ced999a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ced999a","executionInfo":{"status":"ok","timestamp":1718994014345,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"d17924c0-a901-4fb8-be36-93c735ab48e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n","        [  610,   612,   653,  ...,   183,   183,   330]])\n","torch.Size([2, 77728])\n","tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n","        [  615,   794,  2010,  ...,   317,   204,   413]])\n","torch.Size([2, 9716])\n","tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n","        [  811,  1086,  1095,  ...,   585,   585,   183]])\n","torch.Size([2, 9716])\n"]}],"source":["print(train_edge_index)\n","print(train_edge_index.size())\n","print(val_edge_index)\n","print(val_edge_index.size())\n","print(test_edge_index)\n","print(test_edge_index.size())"]},{"cell_type":"code","execution_count":null,"id":"d8a112c1","metadata":{"id":"d8a112c1"},"outputs":[],"source":["# helper function for training and compute BPR loss\n","# since this is a self-supervised learning, we are relying on the graph structure itself and\n","# we don't have label other than the graph structure so we need to the folloing function\n","# which random samples a mini-batch of positive and negative samples\n","def sample_mini_batch(batch_size, edge_index):\n","    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n","\n","    Args:\n","        batch_size (int): minibatch size\n","        edge_index (torch.Tensor): 2 by N list of edges\n","\n","    Returns:\n","        tuple: user indices, positive item indices, negative item indices\n","    \"\"\"\n","    # structured_negative_sampling is a pyG library\n","    # Samples a negative edge :obj:`(i,k)` for every positive edge\n","    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n","    # tuple of the form :obj:`(i,j,k)`.\n","    #\n","    #         >>> edge_index = torch.as_tensor([[0, 0, 1, 2],\n","    #         ...                               [0, 1, 2, 3]])\n","    #         >>> structured_negative_sampling(edge_index)\n","    #         (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n","    edges = structured_negative_sampling(edge_index)\n","\n","    # 3 x edge_index_len\n","    edges = torch.stack(edges, dim=0)\n","\n","    # here is whhen we actually perform the batch sampe\n","    # Return a k sized list of population elements chosen with replacement.\n","    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n","\n","    batch = edges[:, indices]\n","\n","    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n","    return user_indices, pos_item_indices, neg_item_indices"]},{"cell_type":"markdown","id":"3688310d","metadata":{"id":"3688310d"},"source":["# Implementing LightGCN\n","\n","## Light Graph Convolution\n","Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n","\n","\\begin{equation}\n","e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n","\\end{equation}\n","\n","$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n","\n","$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n","\n","$e_u^{(k)}$ : k-th layer user embedding\n","\n","$e_i^{(k)}$ : k-th layer item embedding\n","\n","\n","\n","## Layer Combination and Model Prediction\n","The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n","\n","\n","\\begin{equation}\n","e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n","\\end{equation}\n","\n","$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n","\n","The model prediction is obtained by taking the inner product of the final user and item embeddings.\n","\n","\\begin{equation}\n","\\hat{y}_{ui} = e_u^Te_i\n","\\end{equation}\n","\n","## Matrix Form\n","In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales.\n","\n","\\begin{equation}\n","E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n","\\end{equation}\n","\n","$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n","\n","$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n"]},{"cell_type":"code","execution_count":null,"id":"9e8cbb67","metadata":{"id":"9e8cbb67"},"outputs":[],"source":["# defines LightGCN model\n","class LightGCN(MessagePassing):\n","    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n","    \"\"\"\n","\n","    def __init__(self, num_users,\n","                 num_items,\n","                 embedding_dim=64, # define the embding vector length for each node\n","                 K=3,\n","                 add_self_loops=False):\n","        \"\"\"Initializes LightGCN Model\n","\n","        Args:\n","            num_users (int): Number of users\n","            num_items (int): Number of items\n","            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n","            K (int, optional): Number of message passing layers. Defaults to 3.\n","            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n","        \"\"\"\n","        super().__init__()\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.embedding_dim = embedding_dim\n","        self.K = K\n","        self.add_self_loops = add_self_loops\n","\n","        # define user and item embedding for direct look up.\n","        # embedding dimension: num_user/num_item x embedding_dim\n","\n","        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n","\n","        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n","\n","        # \"Fills the input Tensor with values drawn from the normal distribution\"\n","        # according to LightGCN paper, this gives better performance\n","        nn.init.normal_(self.users_emb.weight, std=0.1)\n","        nn.init.normal_(self.items_emb.weight, std=0.1)\n","\n","    def forward(self, edge_index: Tensor):\n","        \"\"\"Forward propagation of LightGCN Model.\n","\n","        Args:\n","            edge_index (SparseTensor): adjacency matrix\n","\n","        Returns:\n","            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n","        \"\"\"\n","\n","\n","        \"\"\"\n","            compute \\tilde{A}: symmetrically normalized adjacency matrix\n","            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n","\n","            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n","\n","\n","            if your original edge_index look like\n","            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n","                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n","\n","                    torch.Size([2, 99466])\n","\n","            then this will output:\n","                (\n","                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n","                         [   0,    2,    5,  ..., 9444, 9445, 9485]]),\n","                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n","                 )\n","\n","              where edge_index_norm[0] is just the original edge_index\n","\n","              and edge_index_norm[1] is the symmetrically normalization term.\n","\n","            under the hood it's basically doing\n","                def compute_gcn_norm(edge_index, emb):\n","                    emb = emb.weight\n","                    from_, to_ = edge_index\n","                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n","                    deg_inv_sqrt = deg.pow(-0.5)\n","                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n","\n","                    return norm\n","\n","\n","        \"\"\"\n","        print(edge_index)\n","        edge_index_norm = gcn_norm(edge_index=edge_index,\n","                                   add_self_loops=self.add_self_loops)\n","\n","        # concat the user_emb and item_emb as the layer0 embing matrix\n","        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n","        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n","\n","        embs = [emb_0] # save the layer0 emb to the embs list\n","\n","        # emb_k is the emb that we are actually going to push it through the graph layers\n","        # as described in lightGCN paper formula 7\n","        emb_k = emb_0\n","\n","        # push the embedding of all users and items through the Graph Model K times.\n","        # K here is the number of layers\n","        prediction=0\n","\n","        residuals=[]\n","        res_k=torch.zeros((self.num_users,self.num_items))\n","        final_res=torch.zeros((self.num_users,self.num_items))\n","        for i in range(self.K):\n","            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n","            users_emb_k, items_emb_k = torch.split(emb_k, [self.num_users, self.num_items])\n","\n","            embs.append(emb_k)\n","            new_res=users_emb_k @items_emb_k.T\n","            res_k=res_k+new_res\n","\n","            residuals.append(res_k)\n","            final_res+=new_res\n","\n","\n","\n","\n","        # this is doing the formula8 in LightGCN paper\n","\n","        # the stacked embs is a list of embedding matrix at each layer\n","        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len.\n","        #        e.g: torch.Size([10334, 4, 64])\n","        embs = torch.stack(embs, dim=1)\n","\n","        # From LightGCn paper: \"In our experiments, we find that setting α_k uniformly as 1/(K + 1)\n","        #    leads to good performance in general.\"\n","        print(embs.shape)\n","        emb_final = torch.mean(embs, dim=1) # E^K\n","        print(emb_final.shape)\n","        print(final_res.shape)\n","\n","        # splits into e_u^K and e_i^K\n","        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n","\n","        users_res_final, items_res_final = torch.split(final_res, [self.num_users, self.num_items])\n","\n","        # returns e_u^K, e_u^0, e_i^K, e_i^0\n","        # here using .weight to get the tensor weights from n.Embedding\n","        #return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n","        return users_res_final, self.users_emb.weight, items_res_final, self.items_emb.weight\n","\n","\n","    def message(self, x_j, norm):\n","        # x_j is of shape:  edge_index_len x emb_vector_len\n","        #    e.g: torch.Size([77728, 64]\n","        #\n","        # x_j is basically the embedding of all the neighbors based on the src_list in coo edge index\n","        #\n","        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n","        # paper does but here we are using edge_index rather than Adj Matrix\n","        return norm.view(-1, 1) * x_j\n","\n","layers = 3\n","model = LightGCN(num_users=num_users,\n","                 num_items=num_movies,\n","                 K=layers)"]},{"cell_type":"code","execution_count":null,"id":"ea1884a0","metadata":{"id":"ea1884a0"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ffad4fa8","metadata":{"id":"ffad4fa8"},"source":["# Loss Function\n","\n","\n","\n","We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n","\n","\\begin{equation}\n","L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2\n","\\end{equation}\n","\n","$\\hat{y}_{u}$: predicted score of a positive sample\n","\n","$\\hat{y}_{uj}$: predicted score of a negative sample\n","\n","$\\lambda$: hyperparameter which controls the L2 regularization strength"]},{"cell_type":"code","execution_count":null,"id":"cee24091","metadata":{"id":"cee24091"},"outputs":[],"source":["def bpr_loss(users_emb_final,\n","             users_emb_0,\n","             pos_items_emb_final,\n","             pos_items_emb_0,\n","             neg_items_emb_final,\n","             neg_items_emb_0,\n","             lambda_val):\n","    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n","\n","    Args:\n","        users_emb_final (torch.Tensor): e_u_k\n","        users_emb_0 (torch.Tensor): e_u_0\n","        pos_items_emb_final (torch.Tensor): positive e_i_k\n","        pos_items_emb_0 (torch.Tensor): positive e_i_0\n","        neg_items_emb_final (torch.Tensor): negative e_i_k\n","        neg_items_emb_0 (torch.Tensor): negative e_i_0\n","        lambda_val (float): lambda value for regularization loss term\n","\n","    Returns:\n","        torch.Tensor: scalar bpr loss value\n","    \"\"\"\n","    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n","                             pos_items_emb_0.norm(2).pow(2) +\n","                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n","\n","    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n","    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n","    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n","    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n","\n","\n","    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n","\n","    loss = bpr_loss + reg_loss\n","\n","    return loss"]},{"cell_type":"markdown","id":"e7c5c914","metadata":{"id":"e7c5c914"},"source":["# Evaluation Metrics\n","\n","We evalaluate our model using the following metrics\n","\n","\\begin{equation}\n","\\text{Recall} = \\frac{TP}{TP + FP}\n","\\end{equation}\n","\n","\\begin{equation}\n","\\text{Precision} = \\frac{TP}{TP + FN}\n","\\end{equation}\n","\n","Recall@k and Precision@k is just applying only the topK recommended items and then for the overall\n","Recall@k and Precision@k, it's just averaged by the number of users\n","\n","**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n","\n","\\begin{equation}\n","\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n","\\end{equation}\n","\n","p: a particular rank position\n","\n","$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n","\n","**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n","\n","\\begin{equation}\n","\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n","\\end{equation}\n","\n","$|REL_p|$ : list of items ordered by their relevance up to position p\n","\n","**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n","\n","\\begin{equation}\n","\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n","\\end{equation}\n","\n","Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."]},{"cell_type":"code","execution_count":null,"id":"4a6dc66e","metadata":{"id":"4a6dc66e"},"outputs":[],"source":["def get_user_positive_items(edge_index):\n","    \"\"\"\n","    Generates dictionary of positive items for each user\n","\n","    Args:\n","        edge_index (torch.Tensor): 2 by N list of edges\n","\n","    Returns:\n","        dict: user -> list of positive items for each\n","    \"\"\"\n","\n","    # key: user_id, val: item_id list\n","    user_pos_items = {}\n","\n","    for i in range(edge_index.shape[1]):\n","        user = edge_index[0][i].item()\n","        item = edge_index[1][i].item()\n","\n","        if user not in user_pos_items:\n","            user_pos_items[user] = []\n","\n","        user_pos_items[user].append(item)\n","\n","    return user_pos_items"]},{"cell_type":"code","execution_count":null,"id":"ace2aa34","metadata":{"id":"ace2aa34"},"outputs":[],"source":["# computes recall@K and precision@K\n","def RecallPrecision_ATk(groundTruth, r, k):\n","    \"\"\"Computers recall @ k and precision @ k\n","\n","    Args:\n","        groundTruth (list[list[long]]): list of lists of item_ids. Cntaining highly rated items of each user.\n","                            In other words, this is the list of true_relevant_items for each user\n","\n","        r (list[list[boolean]]): list of lists indicating whether each top k item recommended to each user\n","                            is a top k ground truth (true relevant) item or not\n","\n","        k (int): determines the top k items to compute precision and recall on\n","\n","    Returns:\n","        tuple: recall @ k, precision @ k\n","    \"\"\"\n","\n","    # number of correctly predicted items per user\n","    # -1 here means I want to sum at the inner most dimension\n","    num_correct_pred = torch.sum(r, dim=-1)\n","\n","    # number of items liked by each user in the test set\n","    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n","\n","    recall = torch.mean(num_correct_pred / user_num_liked)\n","    precision = torch.mean(num_correct_pred) / k\n","    return recall.item(), precision.item()"]},{"cell_type":"code","execution_count":null,"id":"fa475ca5","metadata":{"id":"fa475ca5"},"outputs":[],"source":["# computes NDCG@K\n","def NDCGatK_r(groundTruth, r, k):\n","    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n","\n","    Args:\n","        groundTruth (list): list of lists containing highly rated items of each user\n","        r (list): list of lists indicating whether each top k item recommended to each user\n","            is a top k ground truth item or not\n","        k (int): determines the top k items to compute ndcg on\n","\n","    Returns:\n","        float: ndcg @ k\n","    \"\"\"\n","    assert len(r) == len(groundTruth)\n","\n","    test_matrix = torch.zeros((len(r), k))\n","\n","    for i, items in enumerate(groundTruth):\n","        length = min(len(items), k)\n","        test_matrix[i, :length] = 1\n","    max_r = test_matrix\n","    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n","    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n","    dcg = torch.sum(dcg, axis=1)\n","    idcg[idcg == 0.] = 1.\n","    ndcg = dcg / idcg\n","    ndcg[torch.isnan(ndcg)] = 0.\n","    return torch.mean(ndcg).item()"]},{"cell_type":"code","execution_count":null,"id":"fe2d3e12","metadata":{"id":"fe2d3e12"},"outputs":[],"source":["# wrapper function to get evaluation metrics\n","def get_metrics(model,\n","                input_edge_index, # adj_mat based edge index\n","                input_exclude_edge_indices, # adj_mat based exclude edge index\n","                k):\n","    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n","\n","    Args:\n","        model (LighGCN): lightgcn model\n","\n","        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n","\n","        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n","\n","        k (int): determines the top k items to compute metrics on\n","\n","    Returns:\n","        tuple: recall @ k, precision @ k, ndcg @ k\n","    \"\"\"\n","    # get the embedding tensor at layer 0 after training\n","    user_embedding = model.users_emb.weight\n","    item_embedding = model.items_emb.weight\n","\n","\n","    # convert adj_mat based edge index to r_mat based edge index so we have have\n","    # the first list being user_ids and second list being item_ids for the edge index\n","    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n","\n","    # This is to exclude the edges we have seen before in our predicted interaction matrix (r_mat_rating)\n","    # E.g: for validation set, we want want to exclude all the edges in training set\n","    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n","                                      for exclude_edge_index in input_exclude_edge_indices]\n","\n","\n","\n","    # Generate predicted interaction matrix (r_mat_rating)\n","    # (num_users x 64) dot_product (num_item x 64).T\n","    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n","\n","    # shape: num_users x num_item\n","    rating = r_mat_rating\n","\n","    for exclude_edge_index in exclude_edge_indices:\n","        # gets all the positive items for each user from the edge index\n","        # it's a dict: user -> positive item list\n","        user_pos_items = get_user_positive_items(exclude_edge_index)\n","\n","        # get coordinates of all edges to exclude\n","        exclude_users = []\n","        exclude_items = []\n","        for user, items in user_pos_items.items():\n","            # [user] * len(item) can give us [user1, user1, user1...] with len of len(item)\n","            # this makes easier to do the masking below\n","            exclude_users.extend([user] * len(items))\n","            exclude_items.extend(items)\n","\n","        # set the excluded entry in the rat_mat_rating matrix to a very small number\n","        rating[exclude_users, exclude_items] = -(1 << 10)\n","\n","    # get the top k recommended items for each user\n","    _, top_K_items = torch.topk(rating, k=k)\n","\n","    # get all unique users in evaluated split\n","    users = edge_index[0].unique()\n","\n","    # dict of user -> pos_item list\n","    test_user_pos_items = get_user_positive_items(edge_index)\n","\n","    # convert test user pos items dictionary into a list of lists\n","    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n","\n","\n","    # r here is \"pred_relevant_items ∩ actually_relevant_items\" list for each user\n","    r = []\n","    for user in users:\n","        user_true_relevant_item = test_user_pos_items[user.item()]\n","        # list of Booleans to store whether or not a given item in the top_K_items for a given user\n","        # is also present in user_true_relevant_item.\n","        # this is later on used to compute n_rel_and_rec_k\n","        label = list(map(lambda x: x in user_true_relevant_item, top_K_items[user]))\n","        r.append(label)\n","\n","    r = torch.Tensor(np.array(r).astype('float'))\n","\n","    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n","    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n","\n","    return recall, precision, ndcg"]},{"cell_type":"code","execution_count":null,"id":"b69b4158","metadata":{"id":"b69b4158"},"outputs":[],"source":["# wrapper function to evaluate model\n","def evaluation(model,\n","               edge_index, # adj_mat based edge index\n","               exclude_edge_indices,  # adj_mat based exclude edge index\n","               k,\n","               lambda_val\n","              ):\n","    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n","\n","    Args:\n","        model (LighGCN): lightgcn model\n","        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n","        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n","        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n","        k (int): determines the top k items to compute metrics on\n","        lambda_val (float): determines lambda for bpr loss\n","\n","    Returns:\n","        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n","    \"\"\"\n","    # get embeddings\n","    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(edge_index)\n","\n","    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n","\n","    edges = structured_negative_sampling(r_mat_edge_index, contains_neg_self_loops=False)\n","\n","    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n","\n","    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n","\n","    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n","\n","    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n","\n","    loss = bpr_loss(users_emb_final,\n","                    users_emb_0,\n","                    pos_items_emb_final,\n","                    pos_items_emb_0,\n","                    neg_items_emb_final,\n","                    neg_items_emb_0,\n","                    lambda_val).item()\n","\n","\n","    recall, precision, ndcg = get_metrics(model,\n","                                          edge_index,\n","                                          exclude_edge_indices,\n","                                          k)\n","\n","    return loss, recall, precision, ndcg"]},{"cell_type":"code","execution_count":null,"id":"af8b0cc8","metadata":{"id":"af8b0cc8"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"316ba67b","metadata":{"id":"316ba67b"},"source":["# Training\n","\n","Your test set performance should be in line with the following (*K=20*):\n","\n","*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"]},{"cell_type":"code","execution_count":null,"id":"c4cee1b8","metadata":{"id":"c4cee1b8"},"outputs":[],"source":["# define contants\n","ITERATIONS = 10000\n","EPOCHS = 10\n","# ITERATIONS = 500\n","BATCH_SIZE = 1024\n","LR = 1e-3\n","ITERS_PER_EVAL = 200\n","ITERS_PER_LR_DECAY = 200\n","K = 20\n","LAMBDA = 1e-6\n","# LAMBDA = 1/2"]},{"cell_type":"code","execution_count":null,"id":"1d3b2d75","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1d3b2d75","executionInfo":{"status":"ok","timestamp":1718994048951,"user_tz":-120,"elapsed":247,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"8917c001-a5da-46dd-8eb7-34e936b6b13c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device cpu.\n"]}],"source":["# setup\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device {device}.\")\n","\n","\n","model = model.to(device)\n","model.train()\n","\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","\n","edge_index = edge_index.to(device)\n","train_edge_index = train_edge_index.to(device)\n","val_edge_index = val_edge_index.to(device)"]},{"cell_type":"code","execution_count":null,"id":"371bdb47","metadata":{"id":"371bdb47"},"outputs":[],"source":["def get_embs_for_bpr(model, input_edge_index):\n","    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(input_edge_index)\n","\n","\n","    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n","\n","    # mini batching for eval and calculate loss\n","    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n","\n","    # This is to push tensor to device so if we are using GPU\n","    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n","\n","\n","    # we need layer0 embeddings and the final embeddings (computed from 0...K layer) for BPR loss computing\n","    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n","    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n","    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n","\n","    return users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0"]},{"cell_type":"code","execution_count":null,"id":"fcbf4944","metadata":{"id":"fcbf4944"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5b7f792e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475,"referenced_widgets":["ea7c575bff8e475abbbdad6642a089b3","24d544348f2a4f01bdafb466698ca5a0","94b29d2bff2d42cdbb4fded859517011","3b7315361f30441e9dc28611c5a9f6bf","a242eab127b749cdb4df4866c6e517b4","c7d7786b8f194ebbb65238e8f89fb3a0","a3fa4a8c76a3466c8da52c2ae1448697","299e7559062b4be7977efa1c3e59d41f","7a1ee51f58424e38aafc5d7aa6d74a87","b661563e9f5445a7aedde57cad767745","ac202b3908694df180904fab4757b29e"]},"id":"5b7f792e","executionInfo":{"status":"error","timestamp":1719000442162,"user_tz":-120,"elapsed":582,"user":{"displayName":"Ilias Papadimitriou","userId":"10915859671183800222"}},"outputId":"38d359e4-06e0-458e-aea3-1db193614da4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7c575bff8e475abbbdad6642a089b3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n","        [  610,   612,   653,  ...,   183,   183,   330]])\n","torch.Size([10334, 4, 64])\n","torch.Size([10334, 64])\n","torch.Size([610, 9724])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"split_with_sizes expects split_sizes to sum exactly to 610 (input tensor's size at dimension 0), but got split_sizes=[610, 9724]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-03774249ff68>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0musers_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_emb_0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpos_items_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_items_emb_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_items_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_items_emb_0\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0;34m=\u001b[0m \u001b[0mget_embs_for_bpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# loss computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-eefe882f095f>\u001b[0m in \u001b[0;36mget_embs_for_bpr\u001b[0;34m(model, input_edge_index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embs_for_bpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0musers_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_emb_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_emb_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0medge_index_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_adj_mat_edge_index_to_r_mat_edge_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_edge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-71-b2cf8c0215ca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0musers_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_emb_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0musers_res_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_res_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# returns e_u^K, e_u^0, e_i^K, e_i^0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: split_with_sizes expects split_sizes to sum exactly to 610 (input tensor's size at dimension 0), but got split_sizes=[610, 9724]"]}],"source":["# training loop\n","train_losses = []\n","val_losses = []\n","val_recall_at_ks = []\n","\n","for iter in tqdm(range(ITERATIONS)):\n","    # forward propagation\n","    users_emb_final, users_emb_0,  pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0 \\\n","                = get_embs_for_bpr(model, train_edge_index)\n","\n","    # loss computation\n","    train_loss = bpr_loss(users_emb_final,\n","                          users_emb_0,\n","                          pos_items_emb_final,\n","                          pos_items_emb_0,\n","                          neg_items_emb_final,\n","                          neg_items_emb_0,\n","                          LAMBDA)\n","\n","    optimizer.zero_grad()\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # validation set\n","    if iter % ITERS_PER_EVAL == 0:\n","        model.eval()\n","\n","        with torch.no_grad():\n","            val_loss, recall, precision, ndcg = evaluation(model,\n","                                                           val_edge_index,\n","                                                           [train_edge_index],\n","                                                           K,\n","                                                           LAMBDA\n","                                                          )\n","\n","            print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n","\n","            train_losses.append(train_loss.item())\n","            val_losses.append(val_loss)\n","            val_recall_at_ks.append(round(recall, 5))\n","        model.train()\n","\n","    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n","        scheduler.step()"]},{"cell_type":"code","execution_count":null,"id":"423573ef","metadata":{"id":"423573ef"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"dabdd722","metadata":{"id":"dabdd722"},"source":["# Plot"]},{"cell_type":"code","execution_count":null,"id":"6e32fd3b","metadata":{"id":"6e32fd3b"},"outputs":[],"source":["iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n","plt.plot(iters, train_losses, label='train')\n","plt.plot(iters, val_losses, label='validation')\n","plt.xlabel('iteration')\n","plt.ylabel('loss')\n","plt.title('training and validation loss curves')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"203b99c0","metadata":{"id":"203b99c0"},"outputs":[],"source":["f2 = plt.figure()\n","plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n","plt.xlabel('iteration')\n","plt.ylabel('recall_at_k')\n","plt.title('recall_at_k curves')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"c9c96a3f","metadata":{"id":"c9c96a3f","outputId":"5ede2cdc-cb8e-45c6-d8d7-f1b3ed2ca2fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[test_loss: -1202.72192, test_recall@20: 0.12296, test_precision@20: 0.04339, test_ndcg@20: 0.09411\n"]}],"source":["# evaluate on test set\n","model.eval()\n","test_edge_index = test_edge_index.to(device)\n","\n","test_loss, test_recall, test_precision, test_ndcg = evaluation(model,\n","                                                               test_edge_index,\n","                                                               [train_edge_index, val_edge_index],\n","                                                               K,\n","                                                               LAMBDA\n","                                                              )\n","\n","print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"]},{"cell_type":"code","execution_count":null,"id":"fb7489fd","metadata":{"id":"fb7489fd"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"provenance":[],"toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"ea7c575bff8e475abbbdad6642a089b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24d544348f2a4f01bdafb466698ca5a0","IPY_MODEL_94b29d2bff2d42cdbb4fded859517011","IPY_MODEL_3b7315361f30441e9dc28611c5a9f6bf"],"layout":"IPY_MODEL_a242eab127b749cdb4df4866c6e517b4"}},"24d544348f2a4f01bdafb466698ca5a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7d7786b8f194ebbb65238e8f89fb3a0","placeholder":"​","style":"IPY_MODEL_a3fa4a8c76a3466c8da52c2ae1448697","value":"  0%"}},"94b29d2bff2d42cdbb4fded859517011":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_299e7559062b4be7977efa1c3e59d41f","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a1ee51f58424e38aafc5d7aa6d74a87","value":0}},"3b7315361f30441e9dc28611c5a9f6bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b661563e9f5445a7aedde57cad767745","placeholder":"​","style":"IPY_MODEL_ac202b3908694df180904fab4757b29e","value":" 0/10000 [00:00&lt;?, ?it/s]"}},"a242eab127b749cdb4df4866c6e517b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7d7786b8f194ebbb65238e8f89fb3a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3fa4a8c76a3466c8da52c2ae1448697":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"299e7559062b4be7977efa1c3e59d41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a1ee51f58424e38aafc5d7aa6d74a87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b661563e9f5445a7aedde57cad767745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac202b3908694df180904fab4757b29e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}