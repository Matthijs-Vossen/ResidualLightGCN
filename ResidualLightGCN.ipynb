{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import LightGCN\n",
    "from torch_geometric.utils import degree, train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData, InMemoryDataset, download_url, extract_zip\n",
    "\n",
    "class MovieLens100K(InMemoryDataset):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ):\n",
    "        super().__init__(root, transform, pre_transform, force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> list:\n",
    "        return ['u.item', 'u.user', 'u1.base', 'u1.test']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        path = download_url(self.url, self.root)\n",
    "        extract_zip(path, self.root)\n",
    "        os.remove(path)\n",
    "        folder = osp.join(self.root, 'ml-100k')\n",
    "        os.rename(folder, self.raw_dir)\n",
    "\n",
    "    def process(self) -> None:\n",
    "        data = HeteroData()\n",
    "\n",
    "        # Process users:\n",
    "        user_df = pd.read_csv(\n",
    "            osp.join(self.raw_dir, 'u.user'),\n",
    "            sep='|',\n",
    "            header=None,\n",
    "            names=['userId', 'age', 'gender', 'occupation', 'zipCode'],\n",
    "            encoding='ISO-8859-1',\n",
    "        )\n",
    "        data['user'].num_nodes = len(user_df)\n",
    "\n",
    "        # Process movies:\n",
    "        movie_df = pd.read_csv(\n",
    "            osp.join(self.raw_dir, 'u.item'),\n",
    "            sep='|',\n",
    "            header=None,\n",
    "            names=[\n",
    "                \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"IMDb URL\",\n",
    "                \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\",\n",
    "                \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "                \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "            ],\n",
    "            encoding='ISO-8859-1',\n",
    "            usecols=['movieId'],\n",
    "        )\n",
    "        data['movie'].num_nodes = len(movie_df)\n",
    "\n",
    "        # Process edges for training and testing:\n",
    "        edge_attrs = ['edge_index', 'edge_label_index']\n",
    "        for edge_attr, raw_path in zip(edge_attrs, ['u1.base', 'u1.test']):\n",
    "            edges_df = pd.read_csv(\n",
    "                osp.join(self.raw_dir, raw_path),\n",
    "                sep='\\t',\n",
    "                header=None,\n",
    "                names=['userId', 'movieId', 'rating', 'timestamp'],\n",
    "            )\n",
    "            src = edges_df['userId'].values - 1  # Adjusting index to start from 0\n",
    "            dst = edges_df['movieId'].values - 1  # Adjusting index to start from 0\n",
    "            index = torch.tensor(np.array([src, dst]))\n",
    "            data['user', 'rates', 'movie'][edge_attr] = index\n",
    "            if edge_attr == 'edge_index':\n",
    "                data['movie', 'rated_by', 'user'][edge_attr] = index.flip([0])\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 160000], edge_label_index=[2, 20000], node_type=[2625], edge_type=[160000])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath('projectFINAL.ipynb')), '', 'data', 'MovieLens')\n",
    "dataset = MovieLens100K(path)\n",
    "data = dataset[0]\n",
    "num_users, num_movies = data['user'].num_nodes, data['movie'].num_nodes\n",
    "data = data.to_homogeneous().to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils import is_sparse, to_edge_index\n",
    "from typing import List\n",
    "\n",
    "class ResidualLightGCN(LightGCN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_embeddings_per_layer(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> List[Tensor]:\n",
    "        \"\"\"Returns the embeddings of nodes in the graph for each layer.\"\"\"\n",
    "        x = self.embedding.weight\n",
    "        embeddings = [x]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "            embeddings.append(x)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_label_index: OptTensor = None,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Computes rankings for pairs of nodes.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor or SparseTensor): Edge tensor specifying\n",
    "                the connectivity of the graph.\n",
    "            edge_label_index (torch.Tensor, optional): Edge tensor specifying\n",
    "                the node pairs for which to compute rankings or probabilities.\n",
    "                If :obj:`edge_label_index` is set to :obj:`None`, all edges in\n",
    "                :obj:`edge_index` will be used instead. (default: :obj:`None`)\n",
    "            edge_weight (torch.Tensor, optional): The weight of each edge in\n",
    "                :obj:`edge_index`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        if edge_label_index is None:\n",
    "            if is_sparse(edge_index):\n",
    "                edge_label_index, _ = to_edge_index(edge_index)\n",
    "            else:\n",
    "                edge_label_index = edge_index\n",
    "\n",
    "        embeddings = self.get_embeddings_per_layer(edge_index, edge_weight)\n",
    "\n",
    "        pred = torch.zeros(edge_label_index.size(1), device=edge_index.device)\n",
    "        for i, alpha in enumerate(self.alpha):\n",
    "            out_src = embeddings[i][edge_label_index[0]]\n",
    "            out_dst = embeddings[i][edge_label_index[1]]\n",
    "            pred += alpha * (out_src * out_dst).sum(dim=-1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def recommend(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "        src_index: OptTensor = None,\n",
    "        dst_index: OptTensor = None,\n",
    "        k: int = 1,\n",
    "        sorted: bool = True,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Get top-:math:`k` recommendations for nodes in :obj:`src_index`.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor or SparseTensor): Edge tensor specifying\n",
    "                the connectivity of the graph.\n",
    "            edge_weight (torch.Tensor, optional): The weight of each edge in\n",
    "                :obj:`edge_index`. (default: :obj:`None`)\n",
    "            src_index (torch.Tensor, optional): Node indices for which\n",
    "                recommendations should be generated.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            dst_index (torch.Tensor, optional): Node indices which represent\n",
    "                the possible recommendation choices.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            k (int, optional): Number of recommendations. (default: :obj:`1`)\n",
    "            sorted (bool, optional): Whether to sort the recommendations\n",
    "                by score. (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        embeddings = self.get_embeddings_per_layer(edge_index, edge_weight)\n",
    "\n",
    "        out_src = out_dst = sum(alpha * emb for alpha, emb in zip(self.alpha, embeddings))\n",
    "\n",
    "        if src_index is not None:\n",
    "            out_src = out_src[src_index]\n",
    "\n",
    "        if dst_index is not None:\n",
    "            out_dst = out_dst[dst_index]\n",
    "\n",
    "        pred = out_src @ out_dst.t()\n",
    "        top_index = pred.topk(k, dim=-1, sorted=sorted).indices\n",
    "\n",
    "        if dst_index is not None:\n",
    "            top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "        return top_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_label_index=[2, 20000], node_type=[2625], edge_type=[160000], val_pos_edge_index=[2, 8000], test_pos_edge_index=[2, 8000], train_pos_edge_index=[2, 128000], train_neg_adj_mask=[2625, 2625], val_neg_edge_index=[2, 8000], test_neg_edge_index=[2, 8000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Split edges into train/val/test sets\n",
    "data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.1)\n",
    "print(data)\n",
    "\n",
    "train_edge_index = data.train_pos_edge_index\n",
    "val_edge_index = data.val_pos_edge_index\n",
    "test_edge_index = data.test_pos_edge_index\n",
    "\n",
    "batch_size = 512\n",
    "mask = train_edge_index[0] < train_edge_index[1]\n",
    "train_edge_label_index = train_edge_index[:, mask]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    range(train_edge_label_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "model = ResidualLightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for index in tqdm(train_loader):\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        neg_edge_label_index = torch.stack([\n",
    "            pos_edge_label_index[0],\n",
    "            torch.randint(num_users, num_users + num_movies,\n",
    "                          (index.numel(), ), device=device)\n",
    "        ], dim=0)\n",
    "        edge_label_index = torch.cat([\n",
    "            pos_edge_label_index,\n",
    "            neg_edge_label_index,\n",
    "        ], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(data.train_pos_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=edge_label_index.unique(),\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(edge_index, k: int):\n",
    "    model.eval()\n",
    "    embeddings_per_layer = model.get_embeddings_per_layer(data.train_pos_edge_index)\n",
    "    num_layers = len(embeddings_per_layer)\n",
    "\n",
    "    emb = sum(model.alpha[i] * embeddings_per_layer[i] for i in range(num_layers))\n",
    "    user_emb, movie_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    precision = recall = total_examples = total_loss = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = start + batch_size\n",
    "        logits = user_emb[start:end] @ movie_emb.t()\n",
    "\n",
    "        mask = ((train_edge_label_index[0] >= start) &\n",
    "                (train_edge_label_index[0] < end))\n",
    "        logits[train_edge_label_index[0, mask] - start,\n",
    "               train_edge_label_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((edge_index[0] >= start) & (edge_index[0] < end))\n",
    "        ground_truth[edge_index[0, mask] - start,\n",
    "                     edge_index[1, mask] - num_users] = True\n",
    "        node_count = degree(edge_index[0, mask] - start,\n",
    "                            num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        isin_mat = ground_truth.gather(1, topk_index)\n",
    "\n",
    "        precision += float((isin_mat.sum(dim=-1) / k).sum())\n",
    "        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "\n",
    "        # Calculate loss\n",
    "        pos_edge_index = edge_index[:, mask]\n",
    "        neg_edge_index = torch.stack([\n",
    "            pos_edge_index[0],\n",
    "            torch.randint(num_users, num_users + num_movies,\n",
    "                          (pos_edge_index.size(1),), device=device)\n",
    "        ], dim=0)\n",
    "        eval_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "        pos_rank, neg_rank = model(data.train_pos_edge_index, eval_edge_index).chunk(2)\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=eval_edge_index.unique(),\n",
    "        )\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples, precision / total_examples, recall / total_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.3101, Val Precision@20: 0.0849, Val Recall@20: 0.2503, Val Loss: 2.9345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.3022, Val Precision@20: 0.0865, Val Recall@20: 0.2549, Val Loss: 2.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 22.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.3004, Val Precision@20: 0.0867, Val Recall@20: 0.2569, Val Loss: 2.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.3007, Val Precision@20: 0.0869, Val Recall@20: 0.2537, Val Loss: 2.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 20.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.2948, Val Precision@20: 0.0877, Val Recall@20: 0.2589, Val Loss: 2.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.2924, Val Precision@20: 0.0880, Val Recall@20: 0.2613, Val Loss: 2.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29/125 [00:02<00:06, 13.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     val_loss, val_precision, val_recall \u001b[38;5;241m=\u001b[39m test(val_edge_index, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Precision@20: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Recall@20: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m pos_rank, neg_rank \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mtrain_pos_edge_index, edge_label_index)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrecommendation_loss(\n\u001b[1;32m     21\u001b[0m     pos_rank,\n\u001b[1;32m     22\u001b[0m     neg_rank,\n\u001b[1;32m     23\u001b[0m     node_id\u001b[38;5;241m=\u001b[39medge_label_index\u001b[38;5;241m.\u001b[39munique(),\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(loss) \u001b[38;5;241m*\u001b[39m pos_rank\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_recall = 0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "best_model_path = 'best_model_ResidualLightGCN.pth'\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train()\n",
    "    val_loss, val_precision, val_recall = test(val_edge_index, k=20)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Val Precision@20: '\n",
    "          f'{val_precision:.4f}, Val Recall@20: {val_recall:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_recall > best_val_recall:\n",
    "        best_val_recall = val_recall\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}. Best epoch: {best_epoch} with Val Recall@20: {best_val_recall:.4f}')\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision@20: 0.0890, Test Recall@20: 0.2591\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "test_loss, test_precision, test_recall = test(test_edge_index, k=20)\n",
    "print(f'Test Precision@20: {test_precision:.4f}, Test Recall@20: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate regular LightGCN model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LightGCN():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for index in tqdm(train_loader):\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        neg_edge_label_index = torch.stack([\n",
    "            pos_edge_label_index[0],\n",
    "            torch.randint(num_users, num_users + num_movies,\n",
    "                          (index.numel(), ), device=device)\n",
    "        ], dim=0)\n",
    "        edge_label_index = torch.cat([\n",
    "            pos_edge_label_index,\n",
    "            neg_edge_label_index,\n",
    "        ], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(data.train_pos_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=edge_label_index.unique(),\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_LightGCN(edge_index, k: int):\n",
    "    model.eval()\n",
    "    emb = model.get_embedding(data.train_pos_edge_index)\n",
    "    user_emb, movie_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    precision = recall = total_examples = total_loss = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = start + batch_size\n",
    "        logits = user_emb[start:end] @ movie_emb.t()\n",
    "\n",
    "        mask = ((train_edge_label_index[0] >= start) &\n",
    "                (train_edge_label_index[0] < end))\n",
    "        logits[train_edge_label_index[0, mask] - start,\n",
    "               train_edge_label_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((edge_index[0] >= start) & (edge_index[0] < end))\n",
    "        ground_truth[edge_index[0, mask] - start,\n",
    "                     edge_index[1, mask] - num_users] = True\n",
    "        node_count = degree(edge_index[0, mask] - start,\n",
    "                            num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        isin_mat = ground_truth.gather(1, topk_index)\n",
    "\n",
    "        precision += float((isin_mat.sum(dim=-1) / k).sum())\n",
    "        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "\n",
    "        # Calculate loss\n",
    "        pos_edge_index = edge_index[:, mask]\n",
    "        neg_edge_index = torch.stack([\n",
    "            pos_edge_index[0],\n",
    "            torch.randint(num_users, num_users + num_movies,\n",
    "                          (pos_edge_index.size(1),), device=device)\n",
    "        ], dim=0)\n",
    "        eval_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "        pos_rank, neg_rank = model(data.train_pos_edge_index, eval_edge_index).chunk(2)\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=eval_edge_index.unique(),\n",
    "        )\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples, precision / total_examples, recall / total_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.4511, Val Precision@20: 0.0596, Val Recall@20: 0.1753, Val Loss: 3.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.4085, Val Precision@20: 0.0632, Val Recall@20: 0.1860, Val Loss: 3.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.4019, Val Precision@20: 0.0669, Val Recall@20: 0.2033, Val Loss: 3.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.3891, Val Precision@20: 0.0713, Val Recall@20: 0.2195, Val Loss: 3.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.3764, Val Precision@20: 0.0760, Val Recall@20: 0.2331, Val Loss: 3.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.3666, Val Precision@20: 0.0780, Val Recall@20: 0.2421, Val Loss: 3.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.3597, Val Precision@20: 0.0789, Val Recall@20: 0.2433, Val Loss: 3.3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.3519, Val Precision@20: 0.0803, Val Recall@20: 0.2425, Val Loss: 3.2766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.3457, Val Precision@20: 0.0805, Val Recall@20: 0.2417, Val Loss: 3.2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.3404, Val Precision@20: 0.0798, Val Recall@20: 0.2386, Val Loss: 3.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.3371, Val Precision@20: 0.0803, Val Recall@20: 0.2408, Val Loss: 3.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.3342, Val Precision@20: 0.0804, Val Recall@20: 0.2413, Val Loss: 3.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.3345, Val Precision@20: 0.0807, Val Recall@20: 0.2442, Val Loss: 3.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.3252, Val Precision@20: 0.0813, Val Recall@20: 0.2449, Val Loss: 3.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.3244, Val Precision@20: 0.0822, Val Recall@20: 0.2471, Val Loss: 3.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.3210, Val Precision@20: 0.0829, Val Recall@20: 0.2479, Val Loss: 3.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.3184, Val Precision@20: 0.0837, Val Recall@20: 0.2475, Val Loss: 3.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.3155, Val Precision@20: 0.0835, Val Recall@20: 0.2460, Val Loss: 3.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.3113, Val Precision@20: 0.0848, Val Recall@20: 0.2511, Val Loss: 2.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 0.3075, Val Precision@20: 0.0844, Val Recall@20: 0.2510, Val Loss: 2.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Train Loss: 0.3065, Val Precision@20: 0.0859, Val Recall@20: 0.2536, Val Loss: 2.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:07<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Train Loss: 0.3007, Val Precision@20: 0.0860, Val Recall@20: 0.2551, Val Loss: 2.9182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 19.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Train Loss: 0.2980, Val Precision@20: 0.0862, Val Recall@20: 0.2549, Val Loss: 2.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Train Loss: 0.2973, Val Precision@20: 0.0870, Val Recall@20: 0.2546, Val Loss: 2.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Train Loss: 0.2953, Val Precision@20: 0.0870, Val Recall@20: 0.2562, Val Loss: 2.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 21.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Train Loss: 0.2941, Val Precision@20: 0.0881, Val Recall@20: 0.2582, Val Loss: 2.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Train Loss: 0.2937, Val Precision@20: 0.0884, Val Recall@20: 0.2606, Val Loss: 2.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Train Loss: 0.2919, Val Precision@20: 0.0890, Val Recall@20: 0.2644, Val Loss: 2.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:06<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Train Loss: 0.2913, Val Precision@20: 0.0895, Val Recall@20: 0.2651, Val Loss: 2.8580\n"
     ]
    }
   ],
   "source": [
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_recall = 0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "best_model_path_LightGCN = 'best_model_LightGCN.pth'\n",
    "\n",
    "train_losses_LightGCN = []\n",
    "val_losses_LightGCN = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train_LightGCN()\n",
    "    val_loss, val_precision, val_recall = test_LightGCN(val_edge_index, k=20)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Val Precision@20: '\n",
    "          f'{val_precision:.4f}, Val Recall@20: {val_recall:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    train_losses_LightGCN.append(loss)\n",
    "    val_losses_LightGCN.append(val_loss)\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_recall > best_val_recall:\n",
    "        best_val_recall = val_recall\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}. Best epoch: {best_epoch} with Val Recall@20: {best_val_recall:.4f}')\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses_LightGCN, label='Train Loss')\n",
    "plt.plot(val_losses_LightGCN, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision@20: 0.0892, Test Recall@20: 0.2655\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path_LightGCN))\n",
    "test_loss, test_precision, test_recall = test_LightGCN(test_edge_index, k=20)\n",
    "print(f'Test Precision@20: {test_precision:.4f}, Test Recall@20: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
