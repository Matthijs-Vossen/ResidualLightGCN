{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import LightGCN\n",
    "from torch_geometric.utils import degree, train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData, InMemoryDataset, download_url, extract_zip\n",
    "\n",
    "class MovieLens100K(InMemoryDataset):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ):\n",
    "        super().__init__(root, transform, pre_transform, force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> list:\n",
    "        return ['u.item', 'u.user', 'u1.base', 'u1.test']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self) -> None:\n",
    "        path = download_url(self.url, self.root)\n",
    "        extract_zip(path, self.root)\n",
    "        os.remove(path)\n",
    "        folder = osp.join(self.root, 'ml-100k')\n",
    "        os.rename(folder, self.raw_dir)\n",
    "\n",
    "    def process(self) -> None:\n",
    "        data = HeteroData()\n",
    "\n",
    "        # Process users:\n",
    "        user_df = pd.read_csv(\n",
    "            osp.join(self.raw_dir, 'u.user'),\n",
    "            sep='|',\n",
    "            header=None,\n",
    "            names=['userId', 'age', 'gender', 'occupation', 'zipCode'],\n",
    "            encoding='ISO-8859-1',\n",
    "        )\n",
    "        data['user'].num_nodes = len(user_df)\n",
    "\n",
    "        # Process movies:\n",
    "        movie_df = pd.read_csv(\n",
    "            osp.join(self.raw_dir, 'u.item'),\n",
    "            sep='|',\n",
    "            header=None,\n",
    "            names=[\n",
    "                \"movieId\", \"title\", \"releaseDate\", \"videoReleaseDate\", \"IMDb URL\",\n",
    "                \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\",\n",
    "                \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "                \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "            ],\n",
    "            encoding='ISO-8859-1',\n",
    "            usecols=['movieId'],\n",
    "        )\n",
    "        data['movie'].num_nodes = len(movie_df)\n",
    "\n",
    "        # Process edges for training and testing:\n",
    "        edge_attrs = ['edge_index', 'edge_label_index']\n",
    "        for edge_attr, raw_path in zip(edge_attrs, ['u1.base', 'u1.test']):\n",
    "            edges_df = pd.read_csv(\n",
    "                osp.join(self.raw_dir, raw_path),\n",
    "                sep='\\t',\n",
    "                header=None,\n",
    "                names=['userId', 'movieId', 'rating', 'timestamp'],\n",
    "            )\n",
    "            src = edges_df['userId'].values - 1  # Adjusting index to start from 0\n",
    "            dst = edges_df['movieId'].values - 1  # Adjusting index to start from 0\n",
    "            index = torch.tensor(np.array([src, dst]))\n",
    "            data['user', 'rates', 'movie'][edge_attr] = index\n",
    "            if edge_attr == 'edge_index':\n",
    "                data['movie', 'rated_by', 'user'][edge_attr] = index.flip([0])\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 160000], edge_label_index=[2, 20000], node_type=[2625], edge_type=[160000])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath('projectFINAL.ipynb')), '', 'data', 'MovieLens')\n",
    "dataset = MovieLens100K(path)\n",
    "data = dataset[0]\n",
    "num_users, num_movies = data['user'].num_nodes, data['movie'].num_nodes\n",
    "data = data.to_homogeneous().to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils import is_sparse, to_edge_index\n",
    "from typing import List\n",
    "\n",
    "class ResidualLightGCN(LightGCN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_embeddings_per_layer(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> List[Tensor]:\n",
    "        \"\"\"Returns the embeddings of nodes in the graph for each layer.\"\"\"\n",
    "        x = self.embedding.weight\n",
    "        embeddings = [x]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "            embeddings.append(x)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_label_index: OptTensor = None,\n",
    "        edge_weight: OptTensor = None,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Computes rankings for pairs of nodes.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor or SparseTensor): Edge tensor specifying\n",
    "                the connectivity of the graph.\n",
    "            edge_label_index (torch.Tensor, optional): Edge tensor specifying\n",
    "                the node pairs for which to compute rankings or probabilities.\n",
    "                If :obj:`edge_label_index` is set to :obj:`None`, all edges in\n",
    "                :obj:`edge_index` will be used instead. (default: :obj:`None`)\n",
    "            edge_weight (torch.Tensor, optional): The weight of each edge in\n",
    "                :obj:`edge_index`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        if edge_label_index is None:\n",
    "            if is_sparse(edge_index):\n",
    "                edge_label_index, _ = to_edge_index(edge_index)\n",
    "            else:\n",
    "                edge_label_index = edge_index\n",
    "\n",
    "        embeddings = self.get_embeddings_per_layer(edge_index, edge_weight)\n",
    "\n",
    "        pred = torch.zeros(edge_label_index.size(1), device=edge_index.device)\n",
    "        for i, alpha in enumerate(self.alpha):\n",
    "            out_src = embeddings[i][edge_label_index[0]]\n",
    "            out_dst = embeddings[i][edge_label_index[1]]\n",
    "            pred += alpha * (out_src * out_dst).sum(dim=-1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def recommend(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        edge_weight: OptTensor = None,\n",
    "        src_index: OptTensor = None,\n",
    "        dst_index: OptTensor = None,\n",
    "        k: int = 1,\n",
    "        sorted: bool = True,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"Get top-:math:`k` recommendations for nodes in :obj:`src_index`.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor or SparseTensor): Edge tensor specifying\n",
    "                the connectivity of the graph.\n",
    "            edge_weight (torch.Tensor, optional): The weight of each edge in\n",
    "                :obj:`edge_index`. (default: :obj:`None`)\n",
    "            src_index (torch.Tensor, optional): Node indices for which\n",
    "                recommendations should be generated.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            dst_index (torch.Tensor, optional): Node indices which represent\n",
    "                the possible recommendation choices.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            k (int, optional): Number of recommendations. (default: :obj:`1`)\n",
    "            sorted (bool, optional): Whether to sort the recommendations\n",
    "                by score. (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        embeddings = self.get_embeddings_per_layer(edge_index, edge_weight)\n",
    "\n",
    "        out_src = out_dst = sum(alpha * emb for alpha, emb in zip(self.alpha, embeddings))\n",
    "\n",
    "        if src_index is not None:\n",
    "            out_src = out_src[src_index]\n",
    "\n",
    "        if dst_index is not None:\n",
    "            out_dst = out_dst[dst_index]\n",
    "\n",
    "        pred = out_src @ out_dst.t()\n",
    "        top_index = pred.topk(k, dim=-1, sorted=sorted).indices\n",
    "\n",
    "        if dst_index is not None:\n",
    "            top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "        return top_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_label_index=[2, 20000], node_type=[2625], edge_type=[160000], val_pos_edge_index=[2, 8000], test_pos_edge_index=[2, 8000], train_pos_edge_index=[2, 128000], train_neg_adj_mask=[2625, 2625], val_neg_edge_index=[2, 8000], test_neg_edge_index=[2, 8000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Split edges into train/val/test sets\n",
    "data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.1)\n",
    "print(data)\n",
    "\n",
    "train_edge_index = data.train_pos_edge_index\n",
    "val_edge_index = data.val_pos_edge_index\n",
    "test_edge_index = data.test_pos_edge_index\n",
    "\n",
    "batch_size = 512\n",
    "mask = train_edge_index[0] < train_edge_index[1]\n",
    "train_edge_label_index = train_edge_index[:, mask]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    range(train_edge_label_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\"\"\" # Use all message passing edges as training labels:\n",
    "batch_size = 512\n",
    "mask = data.edge_index[0] < data.edge_index[1]\n",
    "train_edge_label_index = data.edge_index[:, mask]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    range(train_edge_label_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ") \"\"\"\n",
    "\n",
    "model = ResidualLightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for index in tqdm(train_loader):\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        neg_edge_label_index = torch.stack([\n",
    "            pos_edge_label_index[0],\n",
    "            torch.randint(num_users, num_users + num_movies,\n",
    "                          (index.numel(), ), device=device)\n",
    "        ], dim=0)\n",
    "        edge_label_index = torch.cat([\n",
    "            pos_edge_label_index,\n",
    "            neg_edge_label_index,\n",
    "        ], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(data.train_pos_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=edge_label_index.unique(),\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(edge_index, k: int):\n",
    "    model.eval()\n",
    "    embeddings_per_layer = model.get_embeddings_per_layer(data.train_pos_edge_index)\n",
    "    num_layers = len(embeddings_per_layer)\n",
    "\n",
    "    emb = sum(model.alpha[i] * embeddings_per_layer[i] for i in range(num_layers))\n",
    "    user_emb, movie_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    precision = recall = total_examples = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = start + batch_size\n",
    "        logits = user_emb[start:end] @ movie_emb.t()\n",
    "\n",
    "        mask = ((train_edge_label_index[0] >= start) &\n",
    "                (train_edge_label_index[0] < end))\n",
    "        logits[train_edge_label_index[0, mask] - start,\n",
    "               train_edge_label_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((edge_index[0] >= start) & (edge_index[0] < end))\n",
    "        ground_truth[edge_index[0, mask] - start,\n",
    "                     edge_index[1, mask] - num_users] = True\n",
    "        node_count = degree(edge_index[0, mask] - start,\n",
    "                            num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        isin_mat = ground_truth.gather(1, topk_index)\n",
    "\n",
    "        precision += float((isin_mat.sum(dim=-1) / k).sum())\n",
    "        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "\n",
    "    return precision / total_examples, recall / total_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:07<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6874, Val Precision@20: 0.0637, Val Recall@20: 0.1609, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:08<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.5438, Val Precision@20: 0.0625, Val Recall@20: 0.1587, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:07<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.4181, Val Precision@20: 0.0657, Val Recall@20: 0.1693, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:07<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3968, Val Precision@20: 0.0701, Val Recall@20: 0.1849, \n",
      "Test Precision@20: 0.0685, Test Recall@20: 0.1908\n"
     ]
    }
   ],
   "source": [
    "patience = 10  # Number of epochs to wait for improvement\n",
    "best_val_precision = 0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    loss = train()\n",
    "    val_precision, val_recall = test(val_edge_index, k=20)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Precision@20: '\n",
    "          f'{val_precision:.4f}, Val Recall@20: {val_recall:.4f}, ')\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_precision > best_val_precision:\n",
    "        best_val_precision = val_precision\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}. Best epoch: {best_epoch} with Val Precision@20: {best_val_precision:.4f}')\n",
    "        break\n",
    "    \n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "test_precision, test_recall = test(test_edge_index, k=20)\n",
    "print(f'Test Precision@20: {test_precision:.4f}, Test Recall@20: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
